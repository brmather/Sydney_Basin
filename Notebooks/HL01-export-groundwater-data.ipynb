{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HL01 - export groundwater data\n",
    "\n",
    "My suggestion would be to extract all the data from water level measurements in your area and then to do a series of filters and smoothing to come up with a reasonable set of boundary conditions for your geological timescale. I assume this includes a boundary for the GAB, which is adjacent to your area.\n",
    "The filters and smoothers I would suggest would be:\n",
    "Discard any data post 2000, I would be worried that the extractions would be to much influencing your water levels, but we can do some statistics on this\n",
    "Calculate long term averages from any timeseries data, and extract single observations\n",
    "Create a spatial map and run some sort of smoothing algorithm (Spatial block averaging?) to create a reasonably consistent map.\n",
    "\n",
    "1. Get a data dump from the groundwater explorer (http://www.bom.gov.au/water/groundwater/explorer/map.shtml) for NSW and Qld,\n",
    "2. Then subset to your geographical area using a mask,\n",
    "3. Discard any bores without water level data\n",
    "4. Get all the bore idâ€™s and feed these into â€œreal time dataâ€ and The Qld equivalent and get all the waterlevel data (I havenâ€™t yet figured out how to data dump that out of the BOM system).\n",
    "5. Then do the filtering and smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import h5py\n",
    "import netCDF4\n",
    "import pycurious\n",
    "import csv\n",
    "import shapefile\n",
    "%matplotlib inline\n",
    "\n",
    "extent_globe = [-180,180,-90,90]\n",
    "extent_australia = [112, 155, -44, -10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bore_shapefile(shape_filename):\n",
    "    \"\"\"\n",
    "    Read borehole information from NGIS shapefile\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    shape_filename : str\n",
    "        file path of the NGIS shapefile\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    boreID : array shape(n,)\n",
    "        unique borehole identifier\n",
    "    lonlat : array shape(n,2)\n",
    "        longitudinal / latitudinal coordinates\n",
    "    coords : array shape(n,2)\n",
    "        eastings / northings in local projected coordinates\n",
    "    proj : array shape(n,)\n",
    "        local projection number\n",
    "    elevation : array shape(n,)\n",
    "        elevation above sea level to well casing\n",
    "    \"\"\"\n",
    "    shp = shpreader.Reader(shape_filename)\n",
    "\n",
    "    n_entries = len(shp)\n",
    "    coords_lonlat = np.empty((n_entries,2))\n",
    "    coords_proj   = np.empty((n_entries,2))\n",
    "    proj          = np.empty(n_entries, dtype=np.int)\n",
    "    elevation     = np.empty(n_entries)\n",
    "    hydroID       = np.empty(n_entries, dtype=np.int)\n",
    "    is_hydro      = np.empty(n_entries, dtype=bool)\n",
    "    drilled_depth = np.empty(n_entries)\n",
    "\n",
    "    i = 0\n",
    "    for record in shp.records():\n",
    "        hydroID[i]       = record.attributes['HydroID']\n",
    "        proj[i]          = record.attributes['Projecti_1']\n",
    "        coords_lonlat[i] = record.attributes['Longitude'], record.attributes['Latitude']\n",
    "        coords_proj[i]   = record.attributes['Easting'], record.attributes['Northing']\n",
    "        elevation[i]     = record.attributes['RefElev']\n",
    "        drilled_depth[i] = record.attributes['DrilledDep']\n",
    "        is_hydro[i]      = record.attributes['WaterCount']\n",
    "        i += 1\n",
    "\n",
    "    shp.close()\n",
    "    mask = np.logical_and(is_hydro, drilled_depth > 0)\n",
    "    return hydroID[mask], coords_lonlat[mask], coords_proj[mask], proj[mask], elevation[mask]\n",
    "\n",
    "def read_water_levels(levels_filename, boreID, min_date=None, max_date=None):\n",
    "    \"\"\"\n",
    "    Read water level information from levels.csv for given boreID\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    levels_filename : str\n",
    "        path to levels.csv file\n",
    "    boreID : array shape(n,)\n",
    "        unique borehole identifier\n",
    "    min_date : datetime\n",
    "        include entries greather than or equal to this datetime\n",
    "    max_date : datetime\n",
    "        include entries less than this datetime\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    levels : array shape(n,)\n",
    "        mean water level in each borehole corresponding to their boreID\n",
    "    levels_std : array shape(n,)\n",
    "        standard deviation of water level in each borehole\n",
    "    \"\"\"\n",
    "    bID, level = np.loadtxt(levels_filename, delimiter=',', usecols=(0,5), skiprows=1, unpack=True)\n",
    "    date = np.loadtxt(levels_filename, delimiter=',', usecols=(3,), skiprows=1, unpack=True, dtype=np.datetime64)\n",
    "    bID = bID.astype(np.int)\n",
    "\n",
    "    if min_date is None and max_date is None:\n",
    "        pass\n",
    "    else:    \n",
    "        # create a range if min_date or max_date is not NoneType\n",
    "        if min_date is None:\n",
    "            min_date = np.datetime64('0')\n",
    "        if max_date is None:\n",
    "            max_date = np.datetime64('3000')\n",
    "        \n",
    "        # filter data to within date range\n",
    "        mask_date = np.logical_and(date >= min_date, date < max_date)\n",
    "        bID = bID[mask_date]\n",
    "        level = level[mask_date]\n",
    "\n",
    "    mean_std_levels = np.empty((len(boreID), 2))\n",
    "\n",
    "    for i, ID in enumerate(boreID):\n",
    "        mask_ID = bID == ID\n",
    "        if mask_ID.any():\n",
    "            level_ID = level[mask_ID]\n",
    "            mean_std_levels[i] = level_ID.mean(), np.std(level_ID)\n",
    "        else:\n",
    "            mean_std_levels[i] = np.nan\n",
    "            \n",
    "    return tuple(mean_std_levels.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "states  =  [\"NSW\", \"VIC\", \"ACT\", \"SA\", \"QLD\", \"TAS\", \"NT\", \"WA\"]\n",
    "shapefilename = \"../Data/gw_shp_{0}/shp_{0}/NGIS_Bore.shp\"\n",
    "levelfilename = \"../Data/gw_shp_{0}/shp_{0}/level_{0}.csv\"\n",
    "\n",
    "\n",
    "gw_data = []\n",
    "for state in states:\n",
    "    sf_state = read_bore_shapefile(shapefilename.format(state))\n",
    "    gw_level = read_water_levels(levelfilename.format(state), sf_state[0], None, np.datetime64('2000'))\n",
    "    \n",
    "    gw_state = np.column_stack([np.c_[sf_state], np.c_[gw_level]])\n",
    "    gw_state = gw_state[~np.isnan(gw_level[0])] # mask out no entries\n",
    "    \n",
    "    gw_data.append(gw_state)\n",
    "\n",
    "# concatenate data\n",
    "gw_data = np.vstack(gw_data)\n",
    "gw_ID         = gw_data[:,0]\n",
    "gw_lonlat     = gw_data[:,1:3]\n",
    "gw_coords     = gw_data[:,3:5]\n",
    "gw_proj       = gw_data[:,5]\n",
    "gw_elevation  = gw_data[:,6]\n",
    "gw_level      = gw_data[:,7]\n",
    "gw_level_std  = gw_data[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "columns = ['ID','lon','lat','easting','northing','projection','elevation','gw_level', 'gw_level_std']\n",
    "\n",
    "df = pd.DataFrame(gw_data, columns=columns)\n",
    "df.to_csv('../Data/NGIS_groundwater_levels_AUS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170333, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
