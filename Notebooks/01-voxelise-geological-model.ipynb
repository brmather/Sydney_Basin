{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Voxelise geological model\n",
    "\n",
    "Import all CSV files and interpolate each surface to a predefined grid over which to solve Darcy flow and heat flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import stripy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from scipy.spatial import cKDTree\n",
    "import cartopy.crs as ccrs\n",
    "import os\n",
    "import conduction\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../Data/\"\n",
    "\n",
    "xmin, xmax = 1e99, 1e-99\n",
    "ymin, ymax = 1e99, 1e-99\n",
    "zmin, zmax = 1e99, 1e-99\n",
    "\n",
    "csvfiles = []\n",
    "for i, f in enumerate(sorted(os.listdir(data_dir))):\n",
    "    if f.endswith('.csv') and f[0:2].isdigit():\n",
    "        csvfiles.append(f)\n",
    "        \n",
    "        xyz = np.loadtxt(data_dir+f, delimiter=',', skiprows=1)\n",
    "        \n",
    "        xmin, ymin, zmin = np.minimum([xmin, ymin, zmin], xyz.min(axis=0))\n",
    "        xmax, ymax, zmax = np.maximum([xmax, ymax, zmax], xyz.max(axis=0))\n",
    "        \n",
    "        print(\"{:35} : av depth {:10.3f} +- {:9.3f} metres\".format(f, xyz[:,-1].mean(), np.std(xyz[:,-1])))\n",
    "\n",
    "csvfiles = list(sorted(csvfiles))\n",
    "\n",
    "print(\" \")\n",
    "print(\"x {:8.3f} -> {:8.3f}\".format(xmin/1e3,xmax/1e3))\n",
    "print(\"y {:8.3f} -> {:8.3f}\".format(ymin/1e3,ymax/1e3))\n",
    "print(\"z {:8.3f} -> {:8.3f}\".format(zmin/1e3,zmax/1e3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export high resolution grids\n",
    "\n",
    "Save to a numpy zip archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx, Ny = 791, 1906\n",
    "\n",
    "Xcoords = np.linspace(xmin, xmax, Nx)\n",
    "Ycoords = np.linspace(ymin, ymax, Ny)\n",
    "\n",
    "xq, yq = np.meshgrid(Xcoords, Ycoords)\n",
    "xq_ = xq.ravel()\n",
    "yq_ = yq.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_grid_prev = np.full((Ny,Nx), zmax)\n",
    "\n",
    "grid_list = []\n",
    "\n",
    "for lith, f in enumerate(csvfiles):\n",
    "\n",
    "    # load the surface and remove duplicates\n",
    "    x,y,z = np.loadtxt(data_dir+f, delimiter=',', skiprows=1, unpack=True)\n",
    "    unique_xy, unique_index = np.unique(np.c_[x,y], axis=0, return_index=True)\n",
    "    x, y = list(unique_xy.T)\n",
    "    z = z[unique_index]\n",
    "\n",
    "    # interpolate to grid\n",
    "    mesh = stripy.Triangulation(x, y, tree=True, permute=True)\n",
    "    mesh.update_tension_factors(z)\n",
    "    z_grid = mesh.interpolate_to_grid(Xcoords, Ycoords, z)\n",
    "    z_near, zierr = mesh.interpolate_nearest(xq_, yq_, z)\n",
    "    z_near = z_near.reshape(z_grid.shape)\n",
    "\n",
    "    # set entries outside tolerance to nearest neighbour interpolant\n",
    "    ztol = 0.1*(np.percentile(z,99) - np.percentile(z,1))\n",
    "    z_mask = np.logical_or(z_grid > z_near + ztol, z_grid < z_near - ztol)\n",
    "    z_grid[z_mask] = z_near[z_mask]\n",
    "\n",
    "    # avoid the gap - make sure we interpolate where we have data\n",
    "    d, idx = mesh.nearest_vertices(xq_, yq_)\n",
    "    dtol = np.sqrt(mesh.areas()).mean()\n",
    "    z_inv_mask = np.logical_or(zierr==1, d > dtol)\n",
    "    z_grid.flat[z_inv_mask] = z_grid_prev.flat[z_inv_mask]\n",
    "\n",
    "    # make sure no layer has negative thickness\n",
    "    z_grid = np.minimum(z_grid, z_grid_prev)\n",
    "\n",
    "    # store for next surface\n",
    "    z_grid_prev = z_grid.copy()\n",
    "    \n",
    "    grid_list.append(z_grid.copy())\n",
    "    \n",
    "    print(\"finished processing {}\".format(f))\n",
    "\n",
    "grid_list = np.array(grid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to npz archive\n",
    "\n",
    "np.savez_compressed(data_dir+\"sydney_basin_surfaces.npz\", layers=np.array(grid_list),\n",
    "                                                          Xcoords=Xcoords,\n",
    "                                                          Ycoords=Ycoords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create surface maps\n",
    "\n",
    "Plot the undulation of each geological surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "extent_local = [xmin,xmax,ymin,ymax]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(5,4, sharex=True, sharey=True, figsize=(14,35))\n",
    "\n",
    "i = 0\n",
    "for rax in axes:\n",
    "    for ax in rax:\n",
    "        x,y,z = np.loadtxt(data_dir+csvfiles[i], delimiter=',', skiprows=1, unpack=True)\n",
    "        \n",
    "        im = ax.scatter(x,y,c=z, cmap='terrain', vmin=-5e3, vmax=1e3)\n",
    "        fig.colorbar(im, ax=ax, shrink=0.4)\n",
    "        ax.set_title(csvfiles[i])\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if i == len(grid_list):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "extent_local = [xmin,xmax,ymin,ymax]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(5,4, sharex=True, sharey=True, figsize=(14,35))\n",
    "\n",
    "i = 0\n",
    "for rax in axes:\n",
    "    for ax in rax:\n",
    "        im = ax.imshow(grid_list[i], extent=extent_local, origin='lower', cmap='terrain', vmin=-5e3, vmax=1e3)\n",
    "        fig.colorbar(im, ax=ax, shrink=0.4)\n",
    "        ax.set_title(csvfiles[i])\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if i == len(grid_list):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create thickness maps\n",
    "\n",
    "# dzgrid_list = np.diff(np.array(grid_list), axis=0)\n",
    "grid_prev = np.full_like(grid_list[0], zmax)\n",
    "\n",
    "fig, axes = plt.subplots(5,4, sharex=True, sharey=True, figsize=(14,35))\n",
    "\n",
    "i = 0\n",
    "for rax in axes:\n",
    "    for ax in rax:\n",
    "        dzgrid = grid_list[i] - grid_prev\n",
    "        \n",
    "        im = ax.imshow(dzgrid, extent=extent_local, origin='lower', cmap='terrain')\n",
    "        fig.colorbar(im, ax=ax, shrink=0.4)\n",
    "        ax.set_title(csvfiles[i])\n",
    "        \n",
    "        grid_prev = grid_list[i]\n",
    "        i += 1\n",
    "        \n",
    "        if i == len(grid_list):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now load geological model\n",
    "\n",
    "In a parallel-safe way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup model resolution\n",
    "\n",
    "# global size\n",
    "Nx, Ny, Nz = 101, 101, 201\n",
    "\n",
    "# get local grid\n",
    "solver = conduction.ConductionND((xmin,ymin,zmin), (xmax,ymax,zmax), (Nx,Ny,Nz))\n",
    "Xcoords, Ycoords, Zcoords = solver.grid_coords\n",
    "nx, ny, nz = Xcoords.size, Ycoords.size, Zcoords.size\n",
    "\n",
    "tree = cKDTree(solver.coords)\n",
    "\n",
    "xq, yq = np.meshgrid(Xcoords, Ycoords)\n",
    "\n",
    "voxel_model = np.full((nz,ny,nx), -1, dtype=np.int)\n",
    "layer_mask = np.zeros(nz*ny*nx, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(data_dir+\"sydney_basin_surfaces.npz\", \"r\") as npz:\n",
    "    grid_list    = npz[\"layers\"]\n",
    "    grid_Xcoords = npz['Xcoords']\n",
    "    grid_Ycoords = npz['Ycoords']\n",
    "\n",
    "\n",
    "n_layers = grid_list.shape[0]\n",
    "\n",
    "# set up interpolation object\n",
    "interp = interpolate.RegularGridInterpolator((grid_Ycoords, grid_Xcoords), grid_list[0], method=\"linear\")\n",
    "\n",
    "for lith in range(n_layers):\n",
    "    interp.values = grid_list[lith]\n",
    "    z_grid = interp((yq,xq))\n",
    "    \n",
    "    # interpolate to voxel_model\n",
    "    d, idx = tree.query(np.c_[xq.ravel(), yq.ravel(), z_grid.ravel()])\n",
    "    layer_mask.fill(0)\n",
    "    layer_mask[idx] = True\n",
    "    i0, j0, k0 = np.where(layer_mask.reshape(nz,ny,nx))\n",
    "    for i in range(i0.size):\n",
    "        voxel_model[:i0[i], j0[i], k0[i]] = lith+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Save the geological model to HDF5__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_output = \"sydney_basin.h5\"\n",
    "\n",
    "solver.save_mesh_to_hdf5(h5_output)\n",
    "solver.save_field_to_hdf5(h5_output, lithology=voxel_model.ravel())\n",
    "conduction.tools.generateXdmf(h5_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Testing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(data_dir+\"sydney_basin_surfaces.npz\", \"r\") as npz:\n",
    "    grid_list    = npz[\"layers\"]\n",
    "    grid_Xcoords = npz['Xcoords']\n",
    "    grid_Ycoords = npz['Ycoords']\n",
    "\n",
    "# set up interpolation object\n",
    "interp = interpolate.RegularGridInterpolator((grid_Ycoords, grid_Xcoords), grid_list[0], method=\"linear\")\n",
    "\n",
    "# update grid list for top and bottom of model\n",
    "grid_list = list(grid_list)\n",
    "grid_list.append(np.full_like(grid_list[0], zmin))\n",
    "grid_list = np.array(grid_list)\n",
    "\n",
    "n_layers = grid_list.shape[0]\n",
    "\n",
    "# set up interpolation object\n",
    "interp = interpolate.RegularGridInterpolator((grid_Ycoords, grid_Xcoords), grid_list[0], method=\"linear\")\n",
    "\n",
    "\n",
    "cell_centroid = (1092810.4463113246, 6022927.350231495, -5607.06948146214)\n",
    "cx, cy, cz = cell_centroid\n",
    "\n",
    "for lith in range(n_layers):\n",
    "    interp.values = grid_list[lith]\n",
    "    z_interp = interp((cy,cx))\n",
    "    \n",
    "    print(\"{:2} {:10.2f}, {:2f}\".format(lith, z_interp, cz))\n",
    "\n",
    "    # starting from surface and going deeper with each layer\n",
    "    if cz > z_interp:\n",
    "        print(\"stop at {}\".format(lith))\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d, idx = tree.query(cell_centroid)\n",
    "print(voxel_model.flat[idx])\n",
    "\n",
    "layer_mask.fill(0)\n",
    "layer_mask[idx] = True\n",
    "i0, j0, k0 = np.where(layer_mask.reshape(nz,ny,nx))\n",
    "voxel_model[:,j0,k0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
